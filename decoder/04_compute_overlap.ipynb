{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import dataloader_decoder\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn import functional as F\n",
    "import json\n",
    "from decoder_models import *\n",
    "import h5py\n",
    "import torch.multiprocessing\n",
    "torch.multiprocessing.set_sharing_strategy('file_system')\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# import argparse\n",
    "# parser = argparse.ArgumentParser(description='calculate overlap of Decoder model')\n",
    "# parser.add_argument('model_dir', type=str)\n",
    "# args = parser.parse_args()\n",
    "# model_dir = args.model_dir\n",
    "\n",
    "model_dir = '/ltenas8/users/anneclaire/retrieval_202306/decoder/decoder_runs_20230628_newSpectra_wAS/decoderX/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "config = json.load(open(model_dir+'/config.json'))\n",
    "model_name=config['model_name']\n",
    "model = locals()[model_name](config['n_channels'], config['n_hidden_layers'],config['n_input_features'])#.to('cuda')\n",
    "checkpoint = torch.load(config['directory']+'checkpoint.pth')#config['checkpoint_name'])\n",
    "model.load_state_dict(checkpoint['model_state'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = dataloader_decoder.decoder_dataset(config['input_ds_path'], config['syn_dataset_path'], config['target_freq'],\n",
    "                                           i_start_ds = config['i_start_val'], i_end_ds = config['i_start_val']+config['val_size'],\n",
    "                                           i_start_spec = config['i_start_spec'], i_end_spec = config['i_end_spec'],\n",
    "                                           inds_input_features=config['inds_input_vars_'+config['target_freq']],\n",
    "\n",
    "                                           normalize_input = config['normalize_input'],\n",
    "                                           normalize_output = config['normalize_output'],\n",
    "\n",
    "                                           mean_normalization_spec_json = config['normalize_path']+'/means_spec.json',\n",
    "                                           std_normalization_spec_json = config['normalize_path']+'/stds_spec.json',\n",
    "\n",
    "                                           mean_normalization_input_npy = config['normalize_path']+'/means_input.npy',\n",
    "                                           std_normalization_input_npy = config['normalize_path']+'/stds_input.npy',\n",
    "\n",
    "                                           shuffle_pre_train = config['shuffle_pre_train'])\n",
    "\n",
    "N = len(val_dataset)\n",
    "\n",
    "val_dataloader = DataLoader(val_dataset, num_workers=32, batch_size=1000, pin_memory=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_normalization_spec_json = config['normalize_path']+'/means_spec.json'\n",
    "std_normalization_spec_json = config['normalize_path']+'/stds_spec.json'\n",
    "\n",
    "mean_norm_X = json.load(open(mean_normalization_spec_json))['specX']\n",
    "mean_norm_Ka = json.load(open(mean_normalization_spec_json))['specKa']\n",
    "mean_norm_W = json.load(open(mean_normalization_spec_json))['specW']\n",
    "std_norm_X = json.load(open(std_normalization_spec_json))['specX']\n",
    "std_norm_Ka = json.load(open(std_normalization_spec_json))['specKa']\n",
    "std_norm_W = json.load(open(std_normalization_spec_json))['specW']\n",
    "\n",
    "if config['target_freq']=='W':\n",
    "    mean_norm = mean_norm_W\n",
    "    std_norm = std_norm_W\n",
    "elif config['target_freq']=='Ka':\n",
    "    mean_norm = mean_norm_Ka\n",
    "    std_norm = std_norm_Ka\n",
    "elif config['target_freq']=='X':\n",
    "    mean_norm = mean_norm_X\n",
    "    std_norm = std_norm_X\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "100%|██████████| 200/200 [01:38<00:00,  2.11it/s][W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "100%|██████████| 200/200 [01:38<00:00,  2.03it/s]\n"
     ]
    }
   ],
   "source": [
    "total_size=0\n",
    "mean_rec=0\n",
    "total_size2=0\n",
    "mean_rec2=0\n",
    "mean_rec3 = 0\n",
    "total_size3 = 0\n",
    "mean_rec4 = 0\n",
    "total_size4 = 0\n",
    "epochloss=0\n",
    "with torch.no_grad():\n",
    "    for (input_data, target) in tqdm(iter(val_dataloader)):\n",
    "        output = model.decode(input_data)\n",
    "        amplitude = target.max(axis=-1).values*std_norm-target.min(axis=-1).values*std_norm\n",
    "\n",
    "        target_renorm = target*std_norm+mean_norm\n",
    "        output_renorm = output[:,0,:]*std_norm+mean_norm\n",
    "        target_remin = target_renorm -torch.min(target_renorm,axis=-1).values[:,None]\n",
    "        output_remin = (output_renorm -torch.min(target_renorm,axis=-1).values[:,None]).abs()\n",
    "        otmin = torch.min(target_remin,output_remin)\n",
    "        otmax = torch.max(target_remin,output_remin)\n",
    "\n",
    "        # compute first version of overlap on the current batch\n",
    "        overlap3 = .5*(torch.sum(otmin,axis=-1)/torch.sum(output_remin,axis=-1) + torch.sum(otmin,axis=-1)/torch.sum(target_remin,axis=-1))\n",
    "        # store in the mean_rec3 variable, keeping only spectra with amplitude > 4 (essentially to avoid spectra which are all noise)\n",
    "        mean_rec3 += torch.mean(overlap3[amplitude>4])*output[amplitude>4].size(0)\n",
    "        total_size3+=output[amplitude>4].size(0)\n",
    "\n",
    "        # compute second version of overlap on the current batch\n",
    "        overlap4 = torch.sum(otmin,axis=-1)/torch.sum(otmax,axis=-1)\n",
    "        # store in the mean_rec4 variable, keeping only spectra with amplitude > 4\n",
    "        mean_rec4 += torch.mean(overlap4[amplitude>4])*output[amplitude>4].size(0)\n",
    "        total_size4+=output[amplitude>4].size(0)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9729)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_rec3/total_size3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9813)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mean_rec3/total_size3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9693)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_rec3/total_size3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        \n",
    "with open(model_dir+'/overlap_metrics.txt','w') as f:\n",
    "    f.write('recouvrement 3: %.3f\\n'%(mean_rec3/total_size3))\n",
    "    f.write('recouvrement 4: %.3f'%(mean_rec4/total_size4))\n",
    "  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
